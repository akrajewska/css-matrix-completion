{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D True\n"
     ]
    }
   ],
   "source": [
    "from css_matrix_completion.css import uniform\n",
    "from utils.data_generation import create_rank_k_dataset\n",
    "\n",
    "\n",
    "M, M_incomplete, omega, mask_array = create_rank_k_dataset(1000, 1000, 10, gaussian=True)\n",
    "cols_selected = uniform(M, 500)\n",
    "C = M[:, cols_selected]\n",
    "#\n",
    "# M = np.asfortranarray(M)\n",
    "# C = np.asfortranarray(C)\n",
    "# mask_array = np.asfortranarray(mask_array)\n",
    "print(f'D {np.isfortran(C)}')\n",
    "\n",
    "C = np.ascontiguousarray(C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18922/3372862875.py:19: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, F))\n",
      "  return D@Y.T\n",
      "/home/tosia/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/typing/npydecl.py:913: NumbaPerformanceWarning: '@' is faster on contiguous arrays, called on (array(float64, 2d, A), array(float64, 2d, F))\n",
      "  warnings.warn(NumbaPerformanceWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "@nb.njit(nb.float64[:,:](nb.float64[:,:],nb.boolean[:,:], nb.float64[:, :]), parallel=True, nogil=True)\n",
    "def cx(X, ok_mask, D):\n",
    "    # m, n = X.shape\n",
    "    m, n = X.shape\n",
    "    _, k = D.shape\n",
    "    Y = np.zeros((n, k))\n",
    "    # For each row, solve a k-dimensional regression problem\n",
    "    # only over the nonp.isfortran(nzero projection entries. Note that the\n",
    "    # projection changes the least-squares matrix siX so we\n",
    "    # cannot vectorize the outer loop.\n",
    "    for i in nb.prange(n):\n",
    "        si = np.copy(ok_mask[:, i])\n",
    "        sia = X[si, i]\n",
    "        siX = D[si]\n",
    "        Y[i, :] = np.linalg.lstsq(siX, sia)[0]\n",
    "    # print(f'Y {np.isfortran(Y)}')\n",
    "    # print(f'D {np.isfortran(D)}')\n",
    "    # print(f'YT {np.isfortran(Y.T)}')\n",
    "    return D@Y.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 1s, sys: 6min 54s, total: 9min 56s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = cx(M, mask_array, C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from numba import types\n",
    "\n",
    "\n",
    "#@nb.njit(types.Tuple((nb.float64[:], nb.float64[:]))(nb.float64[:,:],nb.float64[:,:]), parallel=True)\n",
    "def fit(XX, yy):\n",
    "    \"\"\"\"Fit a large set of points to a regression\"\"\"\n",
    "    assert XX.shape == yy.shape, \"Inputs mismatched\"\n",
    "    n_pnts, n_samples = XX.shape\n",
    "\n",
    "    scale = np.empty(n_pnts)\n",
    "    offset = np.empty(n_pnts)\n",
    "\n",
    "    for i in nb.prange(n_pnts):\n",
    "        X, y = XX[i], yy[i]\n",
    "        A = np.vstack((np.ones_like(X), X)).T\n",
    "        offset[i], scale[i] =  np.linalg.lstsq(A, y)[0]\n",
    "\n",
    "    return offset, scale\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "XX, yy = np.random.randn(2, 1000,1000)\n",
    "%%time\n",
    "fit(XX, yy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13923/1134940552.py:15: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  Y[i, :] = np.linalg.lstsq(siX, sia)[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-6.81016576,  1.29227445, -1.59384695, ...,  1.82509451,\n         0.71069245, -0.91610306],\n       [-3.68628197,  0.07361209, -2.90964181, ..., -0.16190265,\n         4.09533825,  2.9135026 ],\n       [ 0.6028191 , -1.0232053 , -4.44192259, ..., -1.42835732,\n         1.83011005,  1.32888591],\n       ...,\n       [-0.18568346, -2.3580204 , -0.46859365, ..., -0.90908786,\n        -3.64575814,  2.39929203],\n       [-1.61814118, -1.19700224,  0.41052628, ..., -1.57706502,\n         2.93690241, -0.19560642],\n       [-0.46351974, -2.87743598,  7.42933315, ..., -0.95331787,\n         0.93849256,  2.2059717 ]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cx(X, ok_mask, C):\n",
    "    m, n = X.shape\n",
    "    _, k = C.shape\n",
    "    Y = np.zeros((n, k))\n",
    "    # For each row, solve a k-dimensional regression problem\n",
    "    # only over the nonzero projection entries. Note that the\n",
    "    # projection changes the least-squares matrix siX so we\n",
    "    # cannot vectorize the outer loop.\n",
    "    for i in range(n):\n",
    "        si = ok_mask[:, i]\n",
    "        sia = X[si, i]\n",
    "        siX = C[si]\n",
    "        Y[i, :] = np.linalg.lstsq(siX, sia)[0]\n",
    "    return C@Y.T\n",
    "\n",
    "cx(M, mask_array, C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#@nb.njit(nb.float64[:,:](nb.float64[:,:], nb.float64[:, ::1]), parallel=True)\n",
    "def cx_all(X, D):\n",
    "    # m, n = X.shape\n",
    "    m, n = X.shape\n",
    "    _, k = D.shape\n",
    "    Y = np.zeros((n, k))\n",
    "    # For each row, solve a k-dimensional regression problem\n",
    "    # only over the nonp.isfortran(nzero projection entries. Note that the\n",
    "    # projection changes the least-squares matrix siX so we\n",
    "    # cannot vectorize the outer loop.\n",
    "    for i in nb.prange(n):\n",
    "        sia = X[:, i]\n",
    "        siX = np.ones(D.shape)\n",
    "        Y[i, :] = np.linalg.lstsq(siX, sia)[0]\n",
    "    # print(f'Y {np.isfortran(Y)}')\n",
    "    # print(f'D {np.isfortran(D)}')\n",
    "    # print(f'YT {np.isfortran(Y.T)}')\n",
    "    return Y.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 15s, sys: 7min 45s, total: 11min 1s\n",
      "Wall time: 1min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-3.29018279e+12,  8.07221545e+11,  8.57921840e+11, ...,\n         9.65313640e+11,  1.47952658e+12, -5.10188914e+11],\n       [ 1.10447541e+12, -1.69947717e+11, -3.59894629e+11, ...,\n        -4.06267638e+11, -4.98647537e+11,  3.03114845e+10],\n       [ 1.10447541e+12, -1.69947717e+11, -3.59894629e+11, ...,\n        -4.06267638e+11, -4.98647537e+11,  3.03114845e+10],\n       ...,\n       [-2.77610602e+10, -4.92988318e+09,  1.55946591e+10, ...,\n         1.77004522e+10,  1.27146032e+10,  1.20760959e+10],\n       [-2.77610602e+10, -4.92988318e+09,  1.55946591e+10, ...,\n         1.77004522e+10,  1.27146032e+10,  1.20760959e+10],\n       [-2.77563876e+10, -4.93116524e+09,  1.55935372e+10, ...,\n         1.76991917e+10,  1.27125047e+10,  1.20770098e+10]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cx_all(M, C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15739/2835844481.py:14: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  Y[i, :] = np.linalg.lstsq(siX, sia)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 36s, sys: 8min 24s, total: 15min 1s\n",
      "Wall time: 1min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-3.10162861e+12,  6.19504381e+11,  1.02909056e+12, ...,\n         1.34751404e+12,  1.25290192e+12, -4.48310735e+11],\n       [ 1.05856822e+12, -4.95930967e+10, -4.00858506e+11, ...,\n        -5.54379916e+11, -3.73523619e+11, -1.26645540e+10],\n       [ 1.05856822e+12, -4.95930967e+10, -4.00858506e+11, ...,\n        -5.54379916e+11, -3.73523619e+11, -1.26645540e+10],\n       ...,\n       [-2.81940284e+10, -1.31767255e+10,  1.51228651e+10, ...,\n         2.32289979e+10,  5.10358289e+09,  1.51780139e+10],\n       [-2.81940284e+10, -1.31767255e+10,  1.51228651e+10, ...,\n         2.32289979e+10,  5.10358289e+09,  1.51780139e+10],\n       [-2.81940284e+10, -1.31767255e+10,  1.51228651e+10, ...,\n         2.32289979e+10,  5.10358289e+09,  1.51780139e+10]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cx_all(M, C)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "TypingError",
     "evalue": "Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'compute' of type Module(<module 'dask' from '/home/tosia/.pyenv/versions/3.9.5/lib/python3.8/site-packages/dask/__init__.py'>)\n\nFile \"../../../../../tmp/ipykernel_9418/2537065620.py\", line 27:\n<source missing, REPL/exec in use?>\n\nDuring: typing of get attribute at /tmp/ipykernel_9418/2537065620.py (27)\n\nFile \"../../../../../tmp/ipykernel_9418/2537065620.py\", line 27:\n<source missing, REPL/exec in use?>\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypingError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [12], line 5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdask\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumba\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnb\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;129m@nb\u001B[39m\u001B[38;5;241m.\u001B[39mnjit(nb\u001B[38;5;241m.\u001B[39mfloat64[:,:](nb\u001B[38;5;241m.\u001B[39mfloat64[:,:], nb\u001B[38;5;241m.\u001B[39mfloat64[:, :]), parallel\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, nogil\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mls_grad\u001B[39m(X, Y):\n\u001B[1;32m      6\u001B[0m     _, s, _ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mlinalg\u001B[38;5;241m.\u001B[39msvd(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m X\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mdot(X))\n\u001B[1;32m      7\u001B[0m     step_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m s \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1e-8\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/decorators.py:219\u001B[0m, in \u001B[0;36m_jit.<locals>.wrapper\u001B[0;34m(func)\u001B[0m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m typeinfer\u001B[38;5;241m.\u001B[39mregister_dispatcher(disp):\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m sig \u001B[38;5;129;01min\u001B[39;00m sigs:\n\u001B[0;32m--> 219\u001B[0m             \u001B[43mdisp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43msig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    220\u001B[0m         disp\u001B[38;5;241m.\u001B[39mdisable_compile()\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m disp\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/dispatcher.py:965\u001B[0m, in \u001B[0;36mDispatcher.compile\u001B[0;34m(self, sig)\u001B[0m\n\u001B[1;32m    963\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m ev\u001B[38;5;241m.\u001B[39mtrigger_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnumba:compile\u001B[39m\u001B[38;5;124m\"\u001B[39m, data\u001B[38;5;241m=\u001B[39mev_details):\n\u001B[1;32m    964\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 965\u001B[0m         cres \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    966\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mForceLiteralArg \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    967\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfolded\u001B[39m(args, kws):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/dispatcher.py:129\u001B[0m, in \u001B[0;36m_FunctionCompiler.compile\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 129\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m retval\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/dispatcher.py:139\u001B[0m, in \u001B[0;36m_FunctionCompiler._compile_cached\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 139\u001B[0m     retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compile_core\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mTypingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_failed_cache[key] \u001B[38;5;241m=\u001B[39m e\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/dispatcher.py:152\u001B[0m, in \u001B[0;36m_FunctionCompiler._compile_core\u001B[0;34m(self, args, return_type)\u001B[0m\n\u001B[1;32m    149\u001B[0m flags \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_customize_flags(flags)\n\u001B[1;32m    151\u001B[0m impl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_implementation(args, {})\n\u001B[0;32m--> 152\u001B[0m cres \u001B[38;5;241m=\u001B[39m \u001B[43mcompiler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_extra\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargetdescr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtyping_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m                              \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargetdescr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_context\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mimpl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m                              \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mflags\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m                              \u001B[49m\u001B[43mpipeline_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpipeline_class\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[38;5;66;03m# Check typing error if object mode is used\u001B[39;00m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cres\u001B[38;5;241m.\u001B[39mtyping_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m flags\u001B[38;5;241m.\u001B[39menable_pyobject:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler.py:716\u001B[0m, in \u001B[0;36mcompile_extra\u001B[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001B[0m\n\u001B[1;32m    692\u001B[0m \u001B[38;5;124;03m\"\"\"Compiler entry point\u001B[39;00m\n\u001B[1;32m    693\u001B[0m \n\u001B[1;32m    694\u001B[0m \u001B[38;5;124;03mParameter\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    712\u001B[0m \u001B[38;5;124;03m    compiler pipeline\u001B[39;00m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    714\u001B[0m pipeline \u001B[38;5;241m=\u001B[39m pipeline_class(typingctx, targetctx, library,\n\u001B[1;32m    715\u001B[0m                           args, return_type, flags, \u001B[38;5;28mlocals\u001B[39m)\n\u001B[0;32m--> 716\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile_extra\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler.py:452\u001B[0m, in \u001B[0;36mCompilerBase.compile_extra\u001B[0;34m(self, func)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mlifted \u001B[38;5;241m=\u001B[39m ()\n\u001B[1;32m    451\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mlifted_from \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 452\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compile_bytecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler.py:520\u001B[0m, in \u001B[0;36mCompilerBase._compile_bytecode\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    516\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;124;03mPopulate and run pipeline for bytecode input\u001B[39;00m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mfunc_ir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 520\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compile_core\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler.py:499\u001B[0m, in \u001B[0;36mCompilerBase._compile_core\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    497\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mstatus\u001B[38;5;241m.\u001B[39mfail_reason \u001B[38;5;241m=\u001B[39m e\n\u001B[1;32m    498\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m is_final_pipeline:\n\u001B[0;32m--> 499\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CompilerError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll available pipelines exhausted\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler.py:486\u001B[0m, in \u001B[0;36mCompilerBase._compile_core\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    484\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    485\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 486\u001B[0m     \u001B[43mpm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    487\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate\u001B[38;5;241m.\u001B[39mcr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler_machinery.py:368\u001B[0m, in \u001B[0;36mPassManager.run\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m    365\u001B[0m msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed in \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m mode pipeline (step: \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m \\\n\u001B[1;32m    366\u001B[0m     (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipeline_name, pass_desc)\n\u001B[1;32m    367\u001B[0m patched_exception \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_patch_error(msg, e)\n\u001B[0;32m--> 368\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m patched_exception\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler_machinery.py:356\u001B[0m, in \u001B[0;36mPassManager.run\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m    354\u001B[0m pass_inst \u001B[38;5;241m=\u001B[39m _pass_registry\u001B[38;5;241m.\u001B[39mget(pss)\u001B[38;5;241m.\u001B[39mpass_inst\n\u001B[1;32m    355\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(pass_inst, CompilerPass):\n\u001B[0;32m--> 356\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_runPass\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpass_inst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLegacy pass in use\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler_lock.py:35\u001B[0m, in \u001B[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_acquire_compile_lock\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m---> 35\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler_machinery.py:311\u001B[0m, in \u001B[0;36mPassManager._runPass\u001B[0;34m(self, index, pss, internal_state)\u001B[0m\n\u001B[1;32m    309\u001B[0m     mutated \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m check(pss\u001B[38;5;241m.\u001B[39mrun_initialization, internal_state)\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SimpleTimer() \u001B[38;5;28;01mas\u001B[39;00m pass_time:\n\u001B[0;32m--> 311\u001B[0m     mutated \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mcheck\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_pass\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minternal_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SimpleTimer() \u001B[38;5;28;01mas\u001B[39;00m finalize_time:\n\u001B[1;32m    313\u001B[0m     mutated \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m check(pss\u001B[38;5;241m.\u001B[39mrun_finalizer, internal_state)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/compiler_machinery.py:273\u001B[0m, in \u001B[0;36mPassManager._runPass.<locals>.check\u001B[0;34m(func, compiler_state)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcheck\u001B[39m(func, compiler_state):\n\u001B[0;32m--> 273\u001B[0m     mangled \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompiler_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mangled \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    275\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompilerPass implementations should return True/False. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    276\u001B[0m                \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompilerPass with name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m did not.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/typed_passes.py:105\u001B[0m, in \u001B[0;36mBaseTypeInference.run_pass\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    100\u001B[0m \u001B[38;5;124;03mType inference and legalization\u001B[39;00m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    102\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m fallback_context(state, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFunction \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m failed type inference\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    103\u001B[0m                       \u001B[38;5;241m%\u001B[39m (state\u001B[38;5;241m.\u001B[39mfunc_id\u001B[38;5;241m.\u001B[39mfunc_name,)):\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;66;03m# Type inference\u001B[39;00m\n\u001B[0;32m--> 105\u001B[0m     typemap, return_type, calltypes, errs \u001B[38;5;241m=\u001B[39m \u001B[43mtype_inference_stage\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtypingctx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtargetctx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_ir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    109\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    110\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    111\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocals\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    112\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraise_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_errors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m     state\u001B[38;5;241m.\u001B[39mtypemap \u001B[38;5;241m=\u001B[39m typemap\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;66;03m# save errors in case of partial typing\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/typed_passes.py:83\u001B[0m, in \u001B[0;36mtype_inference_stage\u001B[0;34m(typingctx, targetctx, interp, args, return_type, locals, raise_errors)\u001B[0m\n\u001B[1;32m     81\u001B[0m     infer\u001B[38;5;241m.\u001B[39mbuild_constraint()\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;66;03m# return errors in case of partial typing\u001B[39;00m\n\u001B[0;32m---> 83\u001B[0m     errs \u001B[38;5;241m=\u001B[39m \u001B[43minfer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraise_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraise_errors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m     typemap, restype, calltypes \u001B[38;5;241m=\u001B[39m infer\u001B[38;5;241m.\u001B[39munify(raise_errors\u001B[38;5;241m=\u001B[39mraise_errors)\n\u001B[1;32m     86\u001B[0m \u001B[38;5;66;03m# Output all Numba warnings\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.9.5/lib/python3.8/site-packages/numba/core/typeinfer.py:1086\u001B[0m, in \u001B[0;36mTypeInferer.propagate\u001B[0;34m(self, raise_errors)\u001B[0m\n\u001B[1;32m   1083\u001B[0m force_lit_args \u001B[38;5;241m=\u001B[39m [e \u001B[38;5;28;01mfor\u001B[39;00m e \u001B[38;5;129;01min\u001B[39;00m errors\n\u001B[1;32m   1084\u001B[0m                   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, ForceLiteralArg)]\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m force_lit_args:\n\u001B[0;32m-> 1086\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m errors[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1087\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m reduce(operator\u001B[38;5;241m.\u001B[39mor_, force_lit_args)\n",
      "\u001B[0;31mTypingError\u001B[0m: Failed in nopython mode pipeline (step: nopython frontend)\nUnknown attribute 'compute' of type Module(<module 'dask' from '/home/tosia/.pyenv/versions/3.9.5/lib/python3.8/site-packages/dask/__init__.py'>)\n\nFile \"../../../../../tmp/ipykernel_9418/2537065620.py\", line 27:\n<source missing, REPL/exec in use?>\n\nDuring: typing of get attribute at /tmp/ipykernel_9418/2537065620.py (27)\n\nFile \"../../../../../tmp/ipykernel_9418/2537065620.py\", line 27:\n<source missing, REPL/exec in use?>\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import numba as nb\n",
    "\n",
    "@nb.njit(nb.float64[:,:](nb.float64[:,:], nb.float64[:, :]), parallel=True, nogil=True)\n",
    "def ls_grad(X, Y):\n",
    "    _, s, _ = np.linalg.svd(2 * X.T.dot(X))\n",
    "    step_size = 1 / s - 1e-8\n",
    "\n",
    "    ## define some parameters\n",
    "    max_steps = 100\n",
    "    tol = 1e-8\n",
    "    beta_hat = np.zeros(100) # initial guess\n",
    "    m, n = X.shape\n",
    "    _, k = Y.shape\n",
    "    Beta = np.zeros((n, k))\n",
    "    for i in nb.prange(n):\n",
    "        y = Y[:, i]\n",
    "        for k in range(max_steps):\n",
    "            Xbeta = X.dot(beta_hat)\n",
    "            func = ((y - Xbeta)**2).sum()\n",
    "            gradient = 2 * X.T.dot(Xbeta - y)\n",
    "\n",
    "            ## Update\n",
    "            obeta = beta_hat\n",
    "            beta_hat = beta_hat - step_size * gradient\n",
    "            new_func = ((y - X.dot(beta_hat))**2).sum()\n",
    "            beta_hat, func, new_func = dask.compute(beta_hat, func, new_func)  # <--- Dask code\n",
    "\n",
    "            ## Check for convergence\n",
    "            change = np.absolute(beta_hat - obeta).max()\n",
    "\n",
    "            if change < tol:\n",
    "                break\n",
    "        Beta[i,:] = beta_hat\n",
    "    return Beta\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import dask\n",
    "def grad_solve_dask(X, y):\n",
    "    _, s, _ = np.linalg.svd(2 * X.T.dot(X))\n",
    "    step_size = 1 / s - 1e-8\n",
    "\n",
    "    ## define some parameters\n",
    "    max_steps = 100\n",
    "    tol = 1e-8\n",
    "    beta_hat = np.zeros_like(y)# initial guess\n",
    "\n",
    "    for k in range(max_steps):\n",
    "        Xbeta = X.dot(beta_hat)\n",
    "        func = ((y - Xbeta)**2).sum()\n",
    "        gradient = 2 * X.T.dot(Xbeta - y)\n",
    "\n",
    "        ## Update\n",
    "        obeta = beta_hat\n",
    "        beta_hat = beta_hat - step_size * gradient\n",
    "        new_func = ((y - X.dot(beta_hat))**2).sum()\n",
    "        beta_hat, func, new_func = dask.compute(beta_hat, func, new_func)  # <--- Dask code\n",
    "\n",
    "        ## Check for convergence\n",
    "        change = np.absolute(beta_hat - obeta).max()\n",
    "\n",
    "        if change < tol:\n",
    "            break\n",
    "    return beta_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#@nb.njit(nb.float64[:](nb.float64[:,:]), nogil=True)\n",
    "def step_size(X):\n",
    "    A = X.T.dot(X)\n",
    "    return A[3]\n",
    "import scipy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4 ms ± 6.32 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "step_size(M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms ± 6.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "step_size(M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 ms ± 70.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "_, s, _ = fbpca.svd(2 * M.T.dot(M))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 ms ± 135 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "_, s, _ = np.linalg.svd(2 * M.T.dot(M))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 ms ± 35.1 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10\n",
    "_, s, _ = scipy.linalg.svd(2 * M.T.dot(M))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 3.53258203e+00, -5.36866908e-01,  2.40689925e+00,  1.30224555e+00,\n       -3.17176930e-01,  2.09848103e+00, -7.40943348e-01, -1.72079575e+00,\n       -2.67649968e+00, -2.10435349e+00, -2.66131205e+00, -6.78008866e-01,\n       -1.00037339e+00, -2.12871844e+00,  2.02384459e+00,  2.78940788e+00,\n        1.06624514e+00,  1.81258258e+00, -7.66224395e-01, -1.59604727e+00,\n        3.36772852e-01, -2.63348098e+00,  1.89061009e+00,  2.76034091e+00,\n       -2.60155693e+00, -1.69257110e+00, -2.30675230e+00, -1.44295694e+00,\n        3.16728159e+00,  4.62913833e+00,  3.02218965e+00, -2.02207060e+00,\n        6.22178665e+00,  2.60753262e+00, -2.07652029e+00,  3.83345298e+00,\n       -1.61079765e+00, -1.14142419e+00, -1.71507140e+00,  4.04740148e+00,\n        4.07226417e+00, -3.26133123e-01, -2.57254583e-01, -4.16734812e+00,\n        1.75494788e-01, -2.71876718e+00, -8.63673658e-01,  1.34165444e+00,\n       -1.38038977e+00,  1.64757847e+00,  2.67253272e-01,  4.44543901e-01,\n        9.37086090e-01, -1.59016523e+00,  1.78382732e+00, -2.38167457e+00,\n        2.38159760e+00, -4.26674846e+00,  3.87809401e+00, -3.73611412e+00,\n        1.65191171e+00,  1.57229501e+00, -1.04397057e+00, -1.32307548e+00,\n        8.81165822e-02, -1.60290907e+00,  4.72994933e-01,  1.59670588e+00,\n        3.57004471e+00, -2.33946221e+00,  2.12919705e+00,  3.54704746e+00,\n        1.68197700e+00,  1.39607949e+00,  1.81644308e+00,  2.76931318e+00,\n       -2.02688032e+00,  1.58266978e+00, -1.32438309e+00, -2.24882857e+00,\n       -5.15916340e-01, -1.31234511e+00, -4.22169487e+00, -2.90913878e+00,\n       -1.86747534e+00,  5.98091360e-01,  1.03677231e-01, -1.21736358e+00,\n        1.01598228e+00,  2.73002305e+00, -3.46122870e-01,  1.77869586e+00,\n       -2.06292878e+00, -1.20518961e+00,  2.43996707e+00,  3.54157613e+00,\n       -4.38354420e+00, -9.05429212e-01, -1.83462447e+00, -7.92499891e-02,\n       -1.20755040e+00,  2.39937415e+00, -1.68109340e+00, -7.69465787e-01,\n       -2.14785861e+00,  8.44762409e-01,  4.24358890e-01,  4.35468356e+00,\n       -1.11478002e+00,  2.08719017e+00,  8.24301438e-01,  1.43606641e+00,\n       -4.48377776e-01, -5.84119765e-01,  1.26801943e+00, -1.07664507e+00,\n        5.56379247e+00,  3.49083645e+00,  1.61053171e+00, -3.68476267e+00,\n       -2.32181730e+00,  5.16049998e-01, -8.09131374e-01,  2.38403316e+00,\n       -6.57154540e-02,  2.54556642e+00, -3.63322388e+00, -2.03310882e+00,\n       -1.19365600e+00, -1.80933634e-01,  1.73170264e-01, -2.37609545e+00,\n       -1.07594379e+00,  4.72623239e+00,  1.36688030e+00,  2.63525090e+00,\n       -4.59064340e+00, -1.47910135e+00, -1.00441234e+00,  9.99163640e-03,\n       -1.48964066e+00,  1.72689827e+00, -9.84925985e-01, -3.29171891e-02,\n        1.09269044e+00, -3.90508560e+00,  1.15182388e+00,  1.67823864e+00,\n        8.48369127e-01, -6.75674247e-01, -3.39113543e+00, -1.30998111e+00,\n       -7.04283001e-01,  4.57954413e-02, -1.41654245e-01, -3.54897067e+00,\n       -3.60499414e-01,  7.61007421e-01,  2.76937941e+00, -1.18873876e+00,\n        2.66901582e+00,  1.18907333e+00, -8.71428734e-01, -1.24280602e-01,\n        1.59640383e+00,  2.94014588e+00, -2.47883276e+00,  1.37313489e+00,\n        2.92624061e+00, -6.97248988e-01, -2.70159723e+00,  8.85779829e-01,\n       -7.68975823e-01,  3.15139328e-01, -3.80364123e+00, -3.61986286e+00,\n        5.19228636e-01,  1.03013052e+00,  2.40928306e+00,  9.21079850e-01,\n        5.10270424e-02,  1.10750267e+00, -1.15745587e+00, -2.08833371e-01,\n       -2.60885573e-01, -2.85708151e-01, -3.16189784e+00,  3.36963204e-01,\n        1.20042566e+00,  1.98956988e+00,  2.53016249e+00, -1.15561842e+00,\n       -5.52249352e-01, -1.51344398e+00,  1.02491229e+00,  5.15968423e-01,\n        1.51497369e+00, -6.73966997e-01, -2.90377610e-01,  2.13386909e+00,\n       -3.12314641e-01, -1.30537596e+00, -9.90960047e-01,  2.23104415e+00,\n        1.60319107e-01, -6.93328178e-01,  8.85722283e-01,  6.94133874e-01,\n        1.64960255e+00, -6.88984538e-01, -2.03810218e+00, -1.12315860e+00,\n       -1.56815853e+00, -3.76560176e-01, -2.64374770e+00, -7.85999696e-01,\n        1.16267618e-01, -8.83360209e-01,  3.16981729e-02,  3.09544785e+00,\n        3.60599107e+00,  5.34490947e+00,  2.87069904e+00,  1.43937300e+00,\n        2.56317770e+00,  1.24933887e+00, -4.37571391e+00, -4.82868542e+00,\n        1.54434485e+00,  6.31244709e-01,  3.31126299e+00, -3.20397117e-01,\n       -1.01197465e+00,  5.38388037e+00,  3.14452238e+00, -1.73422720e-01,\n       -1.98680960e+00, -3.39860474e+00, -1.43070517e+00,  1.07327808e+00,\n        5.58115518e-01, -3.67825063e+00, -7.53234687e-01, -4.12299864e+00,\n       -1.71769170e+00,  1.27608793e+00,  2.01688953e+00,  8.52017132e-01,\n       -3.39056553e+00, -1.65018935e-01, -4.15971043e-01, -9.27387540e-01,\n       -4.01316394e+00,  7.55926007e-01, -2.56885637e+00,  1.92077826e-01,\n        1.89016184e+00, -1.09724120e+00,  1.75739064e+00,  2.35280884e-01,\n       -2.94095677e+00, -4.24006014e-01,  2.08986471e+00,  3.48615061e+00,\n       -2.79957620e+00, -1.61471464e+00, -1.69066729e+00,  1.75171585e-01,\n       -1.22466819e+00, -5.62964905e-01, -8.17355830e-01,  3.64251683e-01,\n       -5.85200416e-01, -3.39978926e+00,  1.01245322e+00,  3.35514709e-01,\n       -4.39749687e-01,  2.25347387e+00, -1.76256418e+00,  2.84037120e+00,\n        5.42375642e-01,  1.51012628e+00, -2.49565039e-01, -7.67297002e+00,\n        9.07578616e-01, -3.77761500e+00, -1.42556982e+00,  3.20321206e-01,\n        3.78417489e+00,  1.38278128e+00,  8.54568457e-01,  1.71313225e+00,\n        7.78777388e-01, -7.75591770e-02,  1.33171310e+00, -9.12042961e-01,\n       -8.64934017e-01, -2.76028853e+00,  5.87341522e-01,  3.10431149e+00,\n        2.87433844e-01, -1.50069569e+00, -3.09646126e+00,  2.58009537e+00,\n       -9.06820652e-01, -7.81642249e-01,  6.30849191e-01,  1.46047799e+00,\n        7.51167047e-01,  2.83753092e+00, -2.60387020e+00, -1.57906484e-01,\n       -1.37000757e+00, -7.26087279e-01,  3.17945348e+00,  1.35263533e+00,\n       -2.70678530e+00,  1.45091608e+00,  2.53717739e-01, -1.85494484e+00,\n        8.52281000e-01, -2.85829539e+00,  4.96423394e+00,  3.02273323e+00,\n       -2.09835903e+00, -4.55622348e-01,  1.36082096e-01,  8.45255134e-01,\n       -2.34605378e-01, -2.58370755e+00, -4.01931217e+00, -6.98045653e-01,\n       -2.80500945e+00, -1.82685083e+00,  1.32765924e+00, -1.03647073e+00,\n        2.28675556e+00,  3.65565534e-01, -1.14321037e+00, -5.78556657e-01,\n       -1.87963033e+00,  4.51393161e-01, -2.35867499e+00, -3.81385643e+00,\n       -1.14922245e+00, -2.02490467e+00, -1.38148403e+00,  2.55473647e+00,\n        4.03710489e-01,  2.04468232e+00,  2.13921891e+00,  7.08303307e-01,\n        3.27672500e-02,  1.74579093e-01, -4.20349387e+00, -1.15505194e+00,\n       -5.29919952e-01, -1.25723700e+00, -1.31207931e+00, -3.92587883e+00,\n        3.52567193e+00,  3.52976752e+00, -7.67874549e-01, -2.95071703e+00,\n       -3.89330305e+00, -4.68501213e-01,  1.17414550e+00, -9.18636077e-01,\n        1.45736711e+00,  5.38765383e-02, -1.38455053e+00, -3.77245589e+00,\n        2.41227483e+00, -3.18591595e-01,  7.01883958e-01, -8.60094155e-02,\n       -6.26122185e-01,  1.27429184e-01,  1.63128234e+00, -6.64847877e-01,\n       -1.57286729e+00, -3.94370732e+00, -2.46580252e+00,  1.61510891e+00,\n       -3.10046527e+00, -2.82232584e+00,  3.92509297e+00, -1.73285449e+00,\n       -1.31407959e+00,  1.42559956e+00,  2.05434882e-02,  2.57927022e+00,\n        4.75522254e-01, -1.64261056e+00,  2.24310776e+00,  2.90570304e+00,\n       -9.85302320e-01, -2.35317696e+00,  8.88479502e-01,  7.13634471e-01,\n       -1.51771103e+00, -2.65562155e-01, -1.11953152e+00, -2.18759187e+00,\n       -2.26039116e+00,  1.25308929e+00,  1.01523017e+00,  1.29470886e+00,\n        1.54705130e-01,  3.88854300e-01,  3.22918129e-01, -1.58889003e+00,\n       -4.70387750e+00, -3.06596954e+00, -4.44598790e+00, -4.21151062e-01,\n       -1.76892580e+00,  2.43292406e+00, -7.07513539e-01, -4.21266681e+00,\n        5.33104120e-01, -1.68067733e+00,  1.76719196e+00, -2.54442502e+00,\n       -3.21273897e-01,  1.18210755e+00, -1.26925783e+00,  2.87542116e-02,\n       -4.38597127e+00,  9.88816287e-01, -2.53028412e+00, -3.56154788e+00,\n       -3.02039487e+00, -1.95850077e-02, -2.12016467e+00,  3.42619340e+00,\n        4.29615221e+00,  6.80080722e-01,  2.14903128e+00, -1.83836386e+00,\n       -7.02872497e-01,  1.29520683e+00, -4.45931094e+00, -2.83425582e+00,\n       -1.55781348e+00,  2.97075149e+00, -1.31389822e+00,  2.22228956e+00,\n        1.84346834e-01, -1.13063876e+00,  7.81480266e-01,  1.13624530e+00,\n        4.53446283e-01,  2.63659194e+00,  1.73339235e+00, -2.74838718e+00,\n        1.81547230e+00,  6.43125819e-01,  2.18251994e+00, -1.43870903e+00,\n        1.95778129e+00, -4.92780741e-01,  8.91552267e-01,  9.16882389e-02,\n       -4.60115090e+00, -9.16654864e-01,  4.16764810e-02,  3.75826882e-01,\n        1.45756621e-01, -4.23676915e-01,  7.46957260e-01, -6.21580475e-01,\n       -3.25660414e+00, -1.43936128e+00, -2.86798058e+00,  5.99677508e-01,\n        5.61671668e+00,  2.47387355e-01, -9.84920076e-01,  7.19670607e-01,\n        7.02200850e-01, -1.66872715e+00,  1.48023899e+00,  3.89912242e+00,\n        6.98570622e-01,  9.70667179e-01, -4.85848359e-01, -4.73861369e-01,\n       -2.76032991e-01, -5.72589876e-01,  1.29621604e-01,  1.76362603e+00,\n        4.65022472e+00,  1.62839094e+00,  3.59369243e+00, -3.86189343e+00,\n       -4.06196937e-01,  2.17936563e-01,  5.06588608e-01, -1.43665912e+00,\n        1.65814892e+00, -1.88388639e-01, -1.22585415e+00, -3.39850502e+00,\n        3.63051053e+00, -4.72822770e-01,  3.75039282e-01, -2.79027090e+00,\n       -1.67222308e+00,  1.15461703e+00, -1.88990310e+00,  5.97279727e-01,\n        1.40394721e+00,  5.15026560e-01,  6.60249284e-01, -6.76819880e-01,\n        2.74050383e+00,  3.65153426e+00,  2.85955576e+00,  1.22384793e+00,\n       -2.25050819e+00,  1.82344798e+00,  3.12900086e+00, -1.09153055e+00,\n        2.40142491e-01, -4.63975539e-01,  4.59926659e+00,  2.21582932e-01,\n       -2.56201497e+00, -1.11734478e+00,  9.70210689e-01,  9.65470069e-01,\n       -9.96034723e-01, -2.40348310e+00,  4.19377183e+00,  8.62262524e-01,\n        2.03217870e+00,  9.17656610e-01, -3.08802879e+00,  2.79265924e+00,\n       -1.01759802e+00,  3.61762712e+00, -7.56069417e-01,  1.15555074e+00,\n        1.59722961e-01,  1.63868224e+00, -1.99660916e+00, -2.20213213e+00,\n       -2.28415360e-01,  3.52850671e+00, -2.40821452e+00, -2.01063524e+00,\n       -1.92339694e-01,  1.95499901e-01,  1.57305285e-01, -2.30116523e+00,\n        1.10226649e+00,  5.11615037e-01,  2.40718276e+00,  3.04909081e-01,\n       -2.58117718e+00,  1.37776240e+00,  7.89499414e-01,  5.23733648e+00,\n        2.78997026e+00, -2.16737124e+00,  6.92640122e-02,  2.89356962e+00,\n       -2.02409676e+00, -6.97581862e-01, -1.95043635e+00,  3.69021001e-01,\n       -2.58462360e+00, -3.55457168e+00, -9.20579881e-01,  8.44046164e-01,\n        1.42883649e+00,  2.53388208e+00,  2.07653365e+00,  1.81463534e+00,\n       -3.87600482e-01, -1.52224072e+00,  2.73775797e+00,  1.06649800e+00,\n        2.33866199e+00, -1.59827050e+00,  1.97324030e+00,  1.54279001e-01,\n        4.36557642e-01,  6.03144985e+00,  6.07870993e-01,  2.44850123e+00,\n       -1.15902595e+00, -2.32201024e+00,  6.04250224e-01, -7.21572968e-01,\n        2.12652927e+00, -2.27274184e+00, -3.74853694e+00,  1.78279485e+00,\n       -5.74390709e-01,  2.19802186e+00, -1.14199849e+00,  3.15116231e-01,\n       -3.29779527e+00,  6.31074258e-01, -6.37897607e-02,  1.85289231e+00,\n       -2.66534648e+00, -2.66208658e+00, -2.33487687e-01,  2.37702948e+00,\n        7.90967793e-01, -4.05160909e-01,  1.85746650e+00, -1.93155126e+00,\n        2.05643456e+00,  3.39489983e+00,  4.16921745e-01, -1.57483465e+00,\n        8.22076635e-03, -3.11268969e+00, -8.34311767e-01,  9.02455993e-01,\n        2.59270927e+00, -1.68144071e+00,  1.69806382e+00,  3.04271030e+00,\n       -2.66887145e+00, -3.49105585e+00, -2.10561413e+00, -1.53273683e+00,\n        9.77447655e-01, -1.03332101e+00,  1.15330841e-01,  6.68394039e-01,\n       -1.01587297e+00, -2.10814277e+00,  3.80586190e-01,  3.25097286e+00,\n        5.24958606e-01, -1.51020485e+00,  9.21700346e-01, -2.74026838e+00,\n        1.63614750e-02,  2.15415129e+00,  1.28202368e+00,  3.58584959e+00,\n        5.56320136e-01, -1.45022271e+00, -1.06709131e+00, -4.03561957e+00,\n       -6.97029899e-01, -9.89537420e-01,  1.85352153e+00, -2.89940800e+00,\n       -3.69010186e+00,  3.09526395e+00,  3.43175143e+00,  4.54520150e+00,\n        1.36637577e+00,  9.79435414e-01,  1.22593907e+00, -1.46493425e+00,\n       -2.72667254e+00,  2.64598011e+00,  6.24329567e-01, -1.06097571e+00,\n       -6.37347930e-01,  9.58618787e-02, -6.65850096e-01,  1.20464886e+00,\n        7.06971966e-01,  4.90161630e+00,  5.10402989e-01,  5.07640281e-01,\n       -1.82781942e+00,  2.15413845e-01, -1.99193404e+00,  7.13663395e-01,\n        3.18739896e+00,  1.26245866e+00,  9.32958862e-01, -2.85212210e+00,\n       -2.55303295e-03, -3.18715423e+00, -9.09327103e-01,  3.05210543e+00,\n        4.45206989e-01, -2.29925749e+00,  2.90994063e+00, -1.94153560e+00,\n       -3.21153750e+00, -2.61883729e+00,  7.28216894e-02, -7.44661887e-01,\n        1.16250984e+00,  5.17778032e+00,  5.72037417e-01, -2.97889952e+00,\n        1.76650155e+00,  1.21565429e-01, -5.20562214e-02,  1.39937065e+00,\n       -4.79824369e-01, -1.72421441e+00, -5.72552222e-01, -1.43587801e+00,\n        4.16812913e-01,  1.71648047e+00,  5.19897938e-01, -1.03055261e+00,\n        4.14545686e-01,  1.33367613e+00,  4.70500568e+00, -8.61748140e-01,\n        1.23916659e-01,  1.83529102e+00,  5.10389302e-01, -1.08113406e+00,\n        2.79526522e+00,  6.78261646e-01,  1.44634100e+00,  1.34860840e+00,\n        9.28480003e-01,  1.00027499e+00, -2.58691854e+00,  1.37973049e+00,\n        2.62378221e+00, -4.66312456e+00, -1.28671728e+00, -1.03001596e+00,\n        4.44726046e-01,  1.03638262e+00,  1.63005225e+00,  2.16568960e+00,\n        1.63574687e+00,  1.64399266e+00, -2.59472359e+00, -1.04094154e+00,\n       -1.25513127e-01, -2.06069737e+00,  1.67036994e+00,  5.39136811e-01,\n        9.34946432e-01,  1.01493848e+00,  7.08375706e-01,  1.38502626e+00,\n        4.55833830e-02, -2.89439232e+00,  1.86552674e+00, -1.58784603e+00,\n       -1.39571491e+00, -8.93492095e-01, -1.49556424e-01,  2.00958939e+00,\n       -2.48199968e+00,  1.37195913e-01, -1.08507752e+00,  7.49168578e-01,\n       -2.04538867e-01,  2.04657772e+00,  1.72578273e+00,  8.59845018e-01,\n       -1.51904574e+00,  1.92780381e+00, -2.59520379e+00,  2.93639281e+00,\n       -8.46047074e-02,  1.25928522e+00, -5.93897666e-02, -2.01646362e-01,\n       -3.40974923e+00, -1.07052629e-01, -6.21050742e+00,  1.96010303e+00,\n        5.68151692e-01, -3.93706336e+00, -3.22995386e+00,  2.25911337e+00,\n        2.55626116e+00,  9.13039604e-01, -1.77535013e+00, -1.88400594e+00,\n       -1.12530116e+00, -1.66932854e+00,  2.46212053e+00, -7.94653479e-01,\n       -3.98934861e-01,  1.12913743e+00,  8.83575026e-01, -3.53891971e-01,\n       -3.48331482e+00, -2.14720433e+00,  2.20145502e+00, -3.86368375e+00,\n        1.54365008e+00, -8.07094635e-01, -9.85192326e-01,  1.67830864e+00,\n        3.70511546e-01,  1.84260548e+00,  3.65957023e-02,  2.21593618e+00,\n       -3.21604192e-01, -1.06563222e+00,  3.48512243e+00,  2.87486372e+00,\n        1.73644586e+00,  6.98044274e-01, -8.75319205e-02,  1.24829493e+00,\n        2.62032570e+00, -1.69727833e+00,  4.39713109e+00,  1.22600186e+00,\n       -1.52622352e+00,  1.87438554e+00,  2.39289162e+00, -2.79610432e+00,\n        6.38885180e-03, -1.20789483e+00,  2.31032055e+00,  1.31998251e+00,\n        2.08998609e+00, -3.40950574e+00, -6.96813572e-01,  6.16926349e+00,\n       -3.21091068e+00, -4.36111765e-01,  5.18285790e-01,  1.70459842e+00,\n        1.54247592e+00, -1.79300408e+00,  6.97684601e-01, -7.73671509e-01,\n       -8.41794836e-01, -2.29771737e+00,  8.59147442e-01,  3.13353108e+00,\n        4.14322694e+00, -1.84773583e-01,  8.49314532e-01,  1.47378216e+00,\n        6.99899782e-01, -8.82403699e-01,  1.70667273e+00,  1.11472837e-01,\n       -1.73523728e+00,  8.58132227e-01, -6.43089786e-02, -3.95159709e+00,\n       -1.33302028e+00,  2.06579939e+00, -2.19626921e-01, -1.18666588e+00,\n       -1.06106487e+00, -1.49085358e+00,  8.67305108e-01,  2.97232751e+00,\n       -2.89814209e+00, -1.07069880e+00,  2.06266703e+00,  2.34423009e-01,\n       -1.18779700e-01,  3.56890868e+00,  8.03867527e-01, -5.63428847e-01,\n        1.82328492e+00,  6.47540364e-01, -1.69539661e+00,  2.32743573e+00,\n       -6.86647737e-01,  2.83857989e-01, -4.63058965e+00, -5.70581869e-01,\n        1.05187093e+00, -2.35824878e+00,  7.71849738e-01,  8.86190968e-01,\n        1.15194040e-01, -2.26744718e+00, -1.94835333e+00,  2.70440402e+00,\n        1.20452728e+00, -1.08526259e+00,  1.45712134e+00,  6.27063410e-01,\n       -4.74812942e-01, -2.31985536e+00,  1.49575683e+00, -4.68996030e-01,\n        2.38139295e+00, -2.14187758e+00, -2.33241988e+00, -3.05849683e+00,\n        1.21336362e+00, -2.61814755e+00, -1.57072934e+00, -5.13093907e-01,\n       -1.18405838e+00,  4.94144096e+00,  1.04606243e+00, -4.66142924e-01,\n        3.95172751e+00, -2.76741210e+00, -2.00249126e-01,  3.03684283e+00,\n       -9.83936116e-02, -3.67626823e+00, -2.65414284e+00, -2.27582026e+00,\n        2.67197693e-01, -1.25858988e+00,  4.64671349e-01, -5.85722900e-01,\n        3.99966914e+00, -1.52426173e+00,  2.38342427e+00,  1.62879460e+00,\n       -4.00623649e-01,  1.79970645e+00, -1.30217049e+00,  1.58097178e+00,\n       -2.09182445e+00, -2.66248587e-01, -5.66906431e-01,  1.62594636e+00,\n       -7.99649996e-01, -2.04265475e+00, -5.48379560e-01,  1.20469958e+00,\n       -8.00818580e-01, -1.94330659e+00, -4.75756387e+00, -1.46611652e+00,\n       -1.80177828e+00, -2.22370350e+00, -2.90114922e+00, -8.16783317e-01,\n       -3.58837281e+00, -2.94948767e-01, -2.33479122e+00, -2.66267685e+00,\n       -1.45083588e+00, -1.60746533e+00, -2.82754976e+00,  5.30207214e-01,\n        3.73786400e+00,  2.10220701e+00, -8.76427941e-01, -1.11909838e+00,\n       -2.10455283e+00,  4.18667500e-01,  2.21253400e+00, -4.28930718e-01,\n        1.24860368e+00, -5.65829415e-02, -2.02107148e+00, -1.16934814e+00,\n       -2.65682498e-01, -2.03023852e+00,  3.53170458e-01, -3.52216968e+00,\n       -2.78132870e+00, -2.46584777e+00, -3.31468448e+00,  9.39217631e-01,\n       -3.83990704e+00, -3.05709378e+00, -2.14725328e+00,  3.45030156e+00,\n        2.00478393e+00, -1.16237979e+00, -5.67106103e-01,  1.55503906e-01,\n        9.12237815e-01, -1.51438693e+00, -2.38462993e+00, -3.94883000e+00,\n        5.72736199e-02,  1.13222012e+00,  1.20946481e+00, -3.84892277e+00,\n       -4.02957871e+00,  1.20387483e+00,  1.50125198e+00, -2.31933234e+00,\n        4.11216549e-01, -2.54654944e+00,  5.92822382e-01, -2.72445704e+00,\n       -8.07670093e-01, -2.30584399e+00,  2.63084278e+00,  1.00602172e+00,\n       -1.18068398e-01, -1.98056711e+00,  4.11803932e+00, -2.23810080e+00])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask_ml.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(M, C[:,1])\n",
    "lr.predict(M)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(1000,)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[:,0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13923/485205517.py:19: RuntimeWarning: overflow encountered in square\n",
      "  new_func = ((y - X.dot(beta_hat))**2).sum()\n",
      "/tmp/ipykernel_13923/485205517.py:13: RuntimeWarning: overflow encountered in square\n",
      "  func = ((y - Xbeta)**2).sum()\n",
      "/tmp/ipykernel_13923/485205517.py:14: RuntimeWarning: overflow encountered in multiply\n",
      "  gradient = 2 * X.T.dot(Xbeta - y)\n",
      "/tmp/ipykernel_13923/485205517.py:18: RuntimeWarning: overflow encountered in multiply\n",
      "  beta_hat = beta_hat - step_size * gradient\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%timeit -n 10\n",
    "c = C[:,1]\n",
    "grad_solve_dask(M, c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "\n",
    "def ls_cvxpy(A, B):\n",
    "\n",
    "    # Define and solve the CVXPY problem.\n",
    "    X = cp.Variable((B.shape[1], A.shape[0]))\n",
    "    cost = cp.norm(B @ X - A)\n",
    "    prob = cp.Problem(cp.Minimize(cost))\n",
    "    prob.solve()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "A = np.random.randn(1000, 1000)\n",
    "B = np.random.randn(1000, 250)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def grad_solve_dask(X, y):\n",
    "    _, s, _ = np.linalg.svd(2 * X.T.dot(X))\n",
    "    step_size = 1 / s - 1e-8\n",
    "    #step_size = 0.01\n",
    "    ## define some parameters\n",
    "    max_steps = 1000\n",
    "    tol = 1e-8\n",
    "    beta_hat = np.zeros(X.shape[1])\n",
    "    for k in range(max_steps):\n",
    "        if k == 18:\n",
    "            print(\"test 18\")\n",
    "        if k == 17:\n",
    "            print(\"test 17\")\n",
    "        Xbeta = X.dot(beta_hat)\n",
    "        func = ((y - Xbeta)**2).sum()\n",
    "        gradient = 2 * X.T.dot(Xbeta - y)\n",
    "\n",
    "        ## Update\n",
    "\n",
    "        obeta = beta_hat\n",
    "        beta_hat = beta_hat - step_size * gradient\n",
    "        new_func = ((y - X.dot(beta_hat))**2).sum()\n",
    "\n",
    "        if np.any(np.isinf(beta_hat)):\n",
    "            print(f\"k {k}\")\n",
    "            print(f\"beta_hat {beta_hat}\")\n",
    "        beta_hat, func, new_func = dask.compute(beta_hat, func, new_func)  # <--- Dask code\n",
    "        if np.any(np.isinf(beta_hat)):\n",
    "            print(f\"k after {k}\")\n",
    "            print(f\"beta_hat {beta_hat}\")\n",
    "        ## Check for convergence\n",
    "        change = np.absolute(beta_hat - obeta).max()\n",
    "\n",
    "        if change < tol:\n",
    "\n",
    "            break\n",
    "    print(f\"Finished after iteration {k}\")\n",
    "    return beta_hat"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "beta = np.random.random(100)  # random beta coefficients, no intercept\n",
    "X = da.random.normal(0, 1, size=(1000000, 100), chunks=(100000, 100))\n",
    "y = X.dot(beta) + da.random.normal(0, 1, size=1000000, chunks=(100000,))\n",
    "X, y = dask.persist(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished after iteration 6\n",
      "CPU times: user 22.1 s, sys: 21.2 s, total: 43.3 s\n",
      "Wall time: 5.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([0.30744387, 0.60097382, 0.89870801, 0.91730935, 0.84380097,\n       0.58354754, 0.94813687, 0.39314319, 0.91918467, 0.50457983,\n       0.11536799, 0.41860291, 0.78037588, 0.06091909, 0.52825152,\n       0.5417035 , 0.57982384, 0.9430732 , 0.10879486, 0.65485137,\n       0.93999317, 0.19723471, 0.80508661, 0.23187837, 0.85316477,\n       0.44496217, 0.42689763, 0.81762567, 0.86590048, 0.11709179,\n       0.96961565, 0.66993136, 0.01673115, 0.01558705, 0.79382082,\n       0.08000898, 0.53470816, 0.08340725, 0.09922097, 0.72581508,\n       0.5420635 , 0.29502586, 0.37575328, 0.82764572, 0.31618451,\n       0.54738382, 0.23788227, 0.90785885, 0.1834257 , 0.71519475,\n       0.54763544, 0.97539503, 0.35701731, 0.44070881, 0.56111234,\n       0.14235804, 0.51670951, 0.34935165, 0.90948178, 0.78920452,\n       0.79918222, 0.57488711, 0.81587038, 0.37491911, 0.11693795,\n       0.07787773, 0.45214053, 0.15540361, 0.40277528, 0.27849452,\n       0.29334935, 0.88155416, 0.98158273, 0.94731701, 0.18627063,\n       0.19895755, 0.5991586 , 0.37410776, 0.75034579, 0.7294789 ,\n       0.36515795, 0.41503743, 0.54387936, 0.08550175, 0.54617652,\n       0.19010845, 0.73801257, 0.98382203, 0.44881461, 0.64803704,\n       0.54945177, 0.6932489 , 0.16791206, 0.50514283, 0.41093457,\n       0.84273416, 0.58664342, 0.77725971, 0.84957105, 0.87723993])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "grad_solve_dask(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
